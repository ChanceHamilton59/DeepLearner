{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = loadmat('test.mat')\n",
    "tdata = x['X']\n",
    "tdata = tdata.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deciding how many nodes wach layer should have\n",
    "\n",
    "n_nodes_inpl = 64  #encoder\n",
    "n_nodes_hl1  = 32  #encoder\n",
    "\n",
    "n_nodes_hl2  = 32  #decoder\n",
    "n_nodes_outl = 64  #decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'weights': <tf.Variable 'Variable:0' shape=(64, 32) dtype=float32_ref>, 'biases': <tf.Variable 'Variable_1:0' shape=(32,) dtype=float32_ref>}\n"
     ]
    }
   ],
   "source": [
    "# first hidden layer has 784*32 weights and 32 biases\n",
    "\n",
    "hidden_1_layer_vals = {\n",
    "'weights':tf.Variable(tf.random_normal([n_nodes_inpl,n_nodes_hl1])),\n",
    "'biases':tf.Variable(tf.random_normal([n_nodes_hl1]))  }\n",
    "print(hidden_1_layer_vals)\n",
    "\n",
    "# second hidden layer has 32*32 weights and 32 biases\n",
    "\n",
    "hidden_2_layer_vals = {\n",
    "'weights':tf.Variable(tf.random_normal([n_nodes_hl1, n_nodes_hl2])),\n",
    "'biases':tf.Variable(tf.random_normal([n_nodes_hl2]))  }\n",
    "\n",
    "# second hidden layer has 32*784 weights and 784 biases\n",
    "\n",
    "output_layer_vals = {\n",
    "'weights':tf.Variable(tf.random_normal([n_nodes_hl2,n_nodes_outl])),\n",
    "'biases':tf.Variable(tf.random_normal([n_nodes_outl])) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image with shape 784 goes in\n",
    "input_layer = tf.placeholder('float', [None, 64])\n",
    "\n",
    "# multiply output of input_layer wth a weight matrix and add biases\n",
    "\n",
    "layer_1 = tf.contrib.layers.fully_connected(\n",
    "       tf.add(tf.matmul(input_layer,hidden_1_layer_vals['weights']),\n",
    "       hidden_1_layer_vals['biases']),32, activation_fn=tf.nn.relu)\n",
    "\n",
    "# multiply output of layer_1 wth a weight matrix and add biases\n",
    "\n",
    "layer_2 = tf.contrib.layers.fully_connected(\n",
    "       tf.add(tf.matmul(layer_1,hidden_2_layer_vals['weights']),\n",
    "       hidden_2_layer_vals['biases']),32, activation_fn=tf.nn.relu)\n",
    "\n",
    "# multiply output of layer_2 wth a weight matrix and add biases\n",
    "\n",
    "output_layer = tf.matmul(layer_2,output_layer_vals['weights']) + output_layer_vals['biases']\n",
    "\n",
    "# output_true shall have the original image for error calculations\n",
    "\n",
    "output_true = tf.placeholder('float', [None, 64])\n",
    "\n",
    "# define our cost function\n",
    "meansq =    tf.reduce_mean(tf.square(output_layer - output_true))\n",
    "\n",
    "# define our optimizer\n",
    "learn_rate = 0.1   # how fast the model should learn\n",
    "optimizer = tf.train.AdagradOptimizer(learn_rate).minimize(meansq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 1000 loss: 2440.135833967477\n",
      "Epoch 1 / 1000 loss: 22.43996875733137\n",
      "Epoch 2 / 1000 loss: 13.395626607351005\n",
      "Epoch 3 / 1000 loss: 12.475011644884944\n",
      "Epoch 4 / 1000 loss: 12.355082189664245\n",
      "Epoch 5 / 1000 loss: 12.33712215255946\n",
      "Epoch 6 / 1000 loss: 12.333955676294863\n",
      "Epoch 7 / 1000 loss: 12.33322089444846\n",
      "Epoch 8 / 1000 loss: 12.332979599945247\n",
      "Epoch 9 / 1000 loss: 12.332875683903694\n",
      "Epoch 10 / 1000 loss: 12.332823619246483\n",
      "Epoch 11 / 1000 loss: 12.332794768735766\n",
      "Epoch 12 / 1000 loss: 12.332777232863009\n",
      "Epoch 13 / 1000 loss: 12.33276879787445\n",
      "Epoch 14 / 1000 loss: 12.332762468606234\n",
      "Epoch 15 / 1000 loss: 12.332756307907403\n",
      "Epoch 16 / 1000 loss: 12.332750163972378\n",
      "Epoch 17 / 1000 loss: 12.332744175568223\n",
      "Epoch 18 / 1000 loss: 12.332738182507455\n",
      "Epoch 19 / 1000 loss: 12.332732238806784\n",
      "Epoch 20 / 1000 loss: 12.332726365886629\n",
      "Epoch 21 / 1000 loss: 12.332720465026796\n",
      "Epoch 22 / 1000 loss: 12.33271467126906\n",
      "Epoch 23 / 1000 loss: 12.332708854228258\n",
      "Epoch 24 / 1000 loss: 12.33270307444036\n",
      "Epoch 25 / 1000 loss: 12.332697184756398\n",
      "Epoch 26 / 1000 loss: 12.33269145525992\n",
      "Epoch 27 / 1000 loss: 12.332685790024698\n",
      "Epoch 28 / 1000 loss: 12.332680159248412\n",
      "Epoch 29 / 1000 loss: 12.332674500532448\n",
      "Epoch 30 / 1000 loss: 12.332668877206743\n",
      "Epoch 31 / 1000 loss: 12.332663238979876\n",
      "Epoch 32 / 1000 loss: 12.332657618448138\n",
      "Epoch 33 / 1000 loss: 12.332652147859335\n",
      "Epoch 34 / 1000 loss: 12.332646641880274\n",
      "Epoch 35 / 1000 loss: 12.332641135901213\n",
      "Epoch 36 / 1000 loss: 12.332635627128184\n",
      "Epoch 37 / 1000 loss: 12.33263015281409\n",
      "Epoch 38 / 1000 loss: 12.332624776288867\n",
      "Epoch 39 / 1000 loss: 12.332619349472225\n",
      "Epoch 40 / 1000 loss: 12.332613996230066\n",
      "Epoch 41 / 1000 loss: 12.332608536817133\n",
      "Epoch 42 / 1000 loss: 12.3326033083722\n",
      "Epoch 43 / 1000 loss: 12.332597989588976\n",
      "Epoch 44 / 1000 loss: 12.332592676393688\n",
      "Epoch 45 / 1000 loss: 12.33258740697056\n",
      "Epoch 46 / 1000 loss: 12.33258218690753\n",
      "Epoch 47 / 1000 loss: 12.332576921209693\n",
      "Epoch 48 / 1000 loss: 12.332571754232049\n",
      "Epoch 49 / 1000 loss: 12.33256652764976\n",
      "Epoch 50 / 1000 loss: 12.332561395131052\n",
      "Epoch 51 / 1000 loss: 12.33255632314831\n",
      "Epoch 52 / 1000 loss: 12.332551192492247\n",
      "Epoch 53 / 1000 loss: 12.332546073012054\n",
      "Epoch 54 / 1000 loss: 12.332540968433022\n",
      "Epoch 55 / 1000 loss: 12.332535929977894\n",
      "Epoch 56 / 1000 loss: 12.332530937157571\n",
      "Epoch 57 / 1000 loss: 12.332525881938636\n",
      "Epoch 58 / 1000 loss: 12.332520935684443\n",
      "Epoch 59 / 1000 loss: 12.332515926100314\n",
      "Epoch 60 / 1000 loss: 12.332511010579765\n",
      "Epoch 61 / 1000 loss: 12.332506055943668\n",
      "Epoch 62 / 1000 loss: 12.332501192577183\n",
      "Epoch 63 / 1000 loss: 12.332496260292828\n",
      "Epoch 64 / 1000 loss: 12.332491407170892\n",
      "Epoch 65 / 1000 loss: 12.332486495375633\n",
      "Epoch 66 / 1000 loss: 12.332481647841632\n",
      "Epoch 67 / 1000 loss: 12.33247686829418\n",
      "Epoch 68 / 1000 loss: 12.332472037523985\n",
      "Epoch 69 / 1000 loss: 12.332467291504145\n",
      "Epoch 70 / 1000 loss: 12.332462521269917\n",
      "Epoch 71 / 1000 loss: 12.332457746379077\n",
      "Epoch 72 / 1000 loss: 12.332453031092882\n",
      "Epoch 73 / 1000 loss: 12.332448369823396\n",
      "Epoch 74 / 1000 loss: 12.332443619146943\n",
      "Epoch 75 / 1000 loss: 12.332438961602747\n",
      "Epoch 76 / 1000 loss: 12.332434320822358\n",
      "Epoch 77 / 1000 loss: 12.33242962602526\n",
      "Epoch 78 / 1000 loss: 12.332425056025386\n",
      "Epoch 79 / 1000 loss: 12.332420385442674\n",
      "Epoch 80 / 1000 loss: 12.332415795885026\n",
      "Epoch 81 / 1000 loss: 12.332411209121346\n",
      "Epoch 82 / 1000 loss: 12.332406693138182\n",
      "Epoch 83 / 1000 loss: 12.332402179948986\n",
      "Epoch 84 / 1000 loss: 12.332397654652596\n",
      "Epoch 85 / 1000 loss: 12.332393089309335\n",
      "Epoch 86 / 1000 loss: 12.332388595677912\n",
      "Epoch 87 / 1000 loss: 12.332384112291038\n",
      "Epoch 88 / 1000 loss: 12.332379648461938\n",
      "Epoch 89 / 1000 loss: 12.332375332713127\n",
      "Epoch 90 / 1000 loss: 12.33237078692764\n",
      "Epoch 91 / 1000 loss: 12.332366354763508\n",
      "Epoch 92 / 1000 loss: 12.332362001761794\n",
      "Epoch 93 / 1000 loss: 12.332357575185597\n",
      "Epoch 94 / 1000 loss: 12.332353158853948\n",
      "Epoch 95 / 1000 loss: 12.33234884776175\n",
      "Epoch 96 / 1000 loss: 12.332344532944262\n",
      "Epoch 97 / 1000 loss: 12.332340212538838\n",
      "Epoch 98 / 1000 loss: 12.332335953600705\n",
      "Epoch 99 / 1000 loss: 12.332331543788314\n",
      "Epoch 100 / 1000 loss: 12.33232735376805\n",
      "Epoch 101 / 1000 loss: 12.332323047332466\n",
      "Epoch 102 / 1000 loss: 12.332318828441203\n",
      "Epoch 103 / 1000 loss: 12.332314549013972\n",
      "Epoch 104 / 1000 loss: 12.332310309633613\n",
      "Epoch 105 / 1000 loss: 12.332306057214737\n",
      "Epoch 106 / 1000 loss: 12.33230187278241\n",
      "Epoch 107 / 1000 loss: 12.332297779619694\n",
      "Epoch 108 / 1000 loss: 12.332293596118689\n",
      "Epoch 109 / 1000 loss: 12.332289388403296\n",
      "Epoch 110 / 1000 loss: 12.332285229116678\n",
      "Epoch 111 / 1000 loss: 12.33228113129735\n",
      "Epoch 112 / 1000 loss: 12.332277028821409\n",
      "Epoch 113 / 1000 loss: 12.332272888161242\n",
      "Epoch 114 / 1000 loss: 12.332268792204559\n",
      "Epoch 115 / 1000 loss: 12.332264713011682\n",
      "Epoch 116 / 1000 loss: 12.332260688766837\n",
      "Epoch 117 / 1000 loss: 12.33225667476654\n",
      "Epoch 118 / 1000 loss: 12.332252627238631\n",
      "Epoch 119 / 1000 loss: 12.3322485787794\n",
      "Epoch 120 / 1000 loss: 12.332244575954974\n",
      "Epoch 121 / 1000 loss: 12.332240561023355\n",
      "Epoch 122 / 1000 loss: 12.332236649468541\n",
      "Epoch 123 / 1000 loss: 12.332232646644115\n",
      "Epoch 124 / 1000 loss: 12.332228706218302\n",
      "Epoch 125 / 1000 loss: 12.332224678248167\n",
      "Epoch 126 / 1000 loss: 12.33222080860287\n",
      "Epoch 127 / 1000 loss: 12.33221684768796\n",
      "Epoch 128 / 1000 loss: 12.332212938927114\n",
      "Epoch 129 / 1000 loss: 12.332209031097591\n",
      "Epoch 130 / 1000 loss: 12.332205123268068\n",
      "Epoch 131 / 1000 loss: 12.332201314158738\n",
      "Epoch 132 / 1000 loss: 12.332197428680956\n",
      "Epoch 133 / 1000 loss: 12.332193518057466\n",
      "Epoch 134 / 1000 loss: 12.33218968193978\n",
      "Epoch 135 / 1000 loss: 12.332185884006321\n",
      "Epoch 136 / 1000 loss: 12.332182049751282\n",
      "Epoch 137 / 1000 loss: 12.332178257405758\n",
      "Epoch 138 / 1000 loss: 12.332174490205944\n",
      "Epoch 139 / 1000 loss: 12.332170683890581\n",
      "Epoch 140 / 1000 loss: 12.332166878506541\n",
      "Epoch 141 / 1000 loss: 12.33216311968863\n",
      "Epoch 142 / 1000 loss: 12.332159344106913\n",
      "Epoch 143 / 1000 loss: 12.332155720330775\n",
      "Epoch 144 / 1000 loss: 12.332151957787573\n",
      "Epoch 145 / 1000 loss: 12.332148130983114\n",
      "Epoch 146 / 1000 loss: 12.332144525833428\n",
      "Epoch 147 / 1000 loss: 12.332140828482807\n",
      "Epoch 148 / 1000 loss: 12.332137080840766\n",
      "Epoch 149 / 1000 loss: 12.332133433781564\n",
      "Epoch 150 / 1000 loss: 12.33212979696691\n",
      "Epoch 151 / 1000 loss: 12.332126104272902\n",
      "Epoch 152 / 1000 loss: 12.332122546620667\n",
      "Epoch 153 / 1000 loss: 12.332118919119239\n",
      "Epoch 154 / 1000 loss: 12.332115200348198\n",
      "Epoch 155 / 1000 loss: 12.332111671566963\n",
      "Epoch 156 / 1000 loss: 12.332108047790825\n",
      "Epoch 157 / 1000 loss: 12.332104361616075\n",
      "Epoch 158 / 1000 loss: 12.332100828178227\n",
      "Epoch 159 / 1000 loss: 12.332097250036895\n",
      "Epoch 160 / 1000 loss: 12.332093701697886\n",
      "Epoch 161 / 1000 loss: 12.332090126350522\n",
      "Epoch 162 / 1000 loss: 12.3320866310969\n",
      "Epoch 163 / 1000 loss: 12.332083060406148\n",
      "Epoch 164 / 1000 loss: 12.332079532556236\n",
      "Epoch 165 / 1000 loss: 12.332075970247388\n",
      "Epoch 166 / 1000 loss: 12.332072529010475\n",
      "Epoch 167 / 1000 loss: 12.33206904027611\n",
      "Epoch 168 / 1000 loss: 12.332065561786294\n",
      "Epoch 169 / 1000 loss: 12.332062115892768\n",
      "Epoch 170 / 1000 loss: 12.332058635540307\n",
      "Epoch 171 / 1000 loss: 12.33205517474562\n",
      "Epoch 172 / 1000 loss: 12.33205168042332\n",
      "Epoch 173 / 1000 loss: 12.332048231735826\n",
      "Epoch 174 / 1000 loss: 12.332044870592654\n",
      "Epoch 175 / 1000 loss: 12.332041439600289\n",
      "Epoch 176 / 1000 loss: 12.332038064487278\n",
      "Epoch 177 / 1000 loss: 12.332034700550139\n",
      "Epoch 178 / 1000 loss: 12.332031241618097\n",
      "Epoch 179 / 1000 loss: 12.332027818076313\n",
      "Epoch 180 / 1000 loss: 12.332024461589754\n",
      "Epoch 181 / 1000 loss: 12.332021180540323\n",
      "Epoch 182 / 1000 loss: 12.33201776072383\n",
      "Epoch 183 / 1000 loss: 12.33201442938298\n",
      "Epoch 184 / 1000 loss: 12.332011093385518\n",
      "Epoch 185 / 1000 loss: 12.332007721066475\n",
      "Epoch 186 / 1000 loss: 12.332004422321916\n",
      "Epoch 187 / 1000 loss: 12.332001100294292\n",
      "Epoch 188 / 1000 loss: 12.3319978332147\n",
      "Epoch 189 / 1000 loss: 12.331994446925819\n",
      "Epoch 190 / 1000 loss: 12.331991310231388\n",
      "Epoch 191 / 1000 loss: 12.331988003104925\n",
      "Epoch 192 / 1000 loss: 12.331984690390527\n",
      "Epoch 193 / 1000 loss: 12.331981412135065\n",
      "Epoch 194 / 1000 loss: 12.331978138536215\n",
      "Epoch 195 / 1000 loss: 12.331974877975881\n",
      "Epoch 196 / 1000 loss: 12.33197171241045\n",
      "Epoch 197 / 1000 loss: 12.331968483515084\n",
      "Epoch 198 / 1000 loss: 12.33196525555104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199 / 1000 loss: 12.3319619204849\n",
      "Epoch 200 / 1000 loss: 12.331958808004856\n",
      "Epoch 201 / 1000 loss: 12.331955620087683\n",
      "Epoch 202 / 1000 loss: 12.331952436827123\n",
      "Epoch 203 / 1000 loss: 12.331949274986982\n",
      "Epoch 204 / 1000 loss: 12.331946154125035\n",
      "Epoch 205 / 1000 loss: 12.331942977383733\n",
      "Epoch 206 / 1000 loss: 12.331939794123173\n",
      "Epoch 207 / 1000 loss: 12.331936664879322\n",
      "Epoch 208 / 1000 loss: 12.331933544948697\n",
      "Epoch 209 / 1000 loss: 12.331930433399975\n",
      "Epoch 210 / 1000 loss: 12.331927263177931\n",
      "Epoch 211 / 1000 loss: 12.331924111582339\n",
      "Epoch 212 / 1000 loss: 12.331920976750553\n",
      "Epoch 213 / 1000 loss: 12.331917903386056\n",
      "Epoch 214 / 1000 loss: 12.33191479742527\n",
      "Epoch 215 / 1000 loss: 12.331911720335484\n",
      "Epoch 216 / 1000 loss: 12.331908703781664\n",
      "Epoch 217 / 1000 loss: 12.33190561272204\n",
      "Epoch 218 / 1000 loss: 12.331902593374252\n",
      "Epoch 219 / 1000 loss: 12.331899493932724\n",
      "Epoch 220 / 1000 loss: 12.331896460615098\n",
      "Epoch 221 / 1000 loss: 12.331893363967538\n",
      "Epoch 222 / 1000 loss: 12.331890393979847\n",
      "Epoch 223 / 1000 loss: 12.331887341104448\n",
      "Epoch 224 / 1000 loss: 12.3318843357265\n",
      "Epoch 225 / 1000 loss: 12.331881262362003\n",
      "Epoch 226 / 1000 loss: 12.331878227181733\n",
      "Epoch 227 / 1000 loss: 12.331875259056687\n",
      "Epoch 228 / 1000 loss: 12.33187232259661\n",
      "Epoch 229 / 1000 loss: 12.33186930604279\n",
      "Epoch 230 / 1000 loss: 12.331866349093616\n",
      "Epoch 231 / 1000 loss: 12.331863397732377\n",
      "Epoch 232 / 1000 loss: 12.331860386766493\n",
      "Epoch 233 / 1000 loss: 12.331857483834028\n",
      "Epoch 234 / 1000 loss: 12.331854491494596\n",
      "Epoch 235 / 1000 loss: 12.331851590424776\n",
      "Epoch 236 / 1000 loss: 12.331848667003214\n",
      "Epoch 237 / 1000 loss: 12.33184573892504\n",
      "Epoch 238 / 1000 loss: 12.331842836923897\n",
      "Epoch 239 / 1000 loss: 12.331839891150594\n",
      "Epoch 240 / 1000 loss: 12.331836925819516\n",
      "Epoch 241 / 1000 loss: 12.331834075041115\n",
      "Epoch 242 / 1000 loss: 12.331831133924425\n",
      "Epoch 243 / 1000 loss: 12.331828239373863\n",
      "Epoch 244 / 1000 loss: 12.331825385801494\n",
      "Epoch 245 / 1000 loss: 12.331822543404996\n",
      "Epoch 246 / 1000 loss: 12.331819662824273\n",
      "Epoch 247 / 1000 loss: 12.331816790625453\n",
      "Epoch 248 / 1000 loss: 12.331813957542181\n",
      "Epoch 249 / 1000 loss: 12.33181109558791\n",
      "Epoch 250 / 1000 loss: 12.331808241084218\n",
      "Epoch 251 / 1000 loss: 12.331805448047817\n",
      "Epoch 252 / 1000 loss: 12.331802558153868\n",
      "Epoch 253 / 1000 loss: 12.331799789331853\n",
      "Epoch 254 / 1000 loss: 12.331796969287097\n",
      "Epoch 255 / 1000 loss: 12.33179411944002\n",
      "Epoch 256 / 1000 loss: 12.331791333854198\n",
      "Epoch 257 / 1000 loss: 12.33178857434541\n",
      "Epoch 258 / 1000 loss: 12.331785790622234\n",
      "Epoch 259 / 1000 loss: 12.33178296405822\n",
      "Epoch 260 / 1000 loss: 12.331780209206045\n",
      "Epoch 261 / 1000 loss: 12.331777432002127\n",
      "Epoch 262 / 1000 loss: 12.331774632446468\n",
      "Epoch 263 / 1000 loss: 12.33177189156413\n",
      "Epoch 264 / 1000 loss: 12.33176910597831\n",
      "Epoch 265 / 1000 loss: 12.331766390241683\n",
      "Epoch 266 / 1000 loss: 12.331763569265604\n",
      "Epoch 267 / 1000 loss: 12.331760847009718\n",
      "Epoch 268 / 1000 loss: 12.331758167594671\n",
      "Epoch 269 / 1000 loss: 12.331755470484495\n",
      "Epoch 270 / 1000 loss: 12.331752733327448\n",
      "Epoch 271 / 1000 loss: 12.331750015728176\n",
      "Epoch 272 / 1000 loss: 12.331747289747\n",
      "Epoch 273 / 1000 loss: 12.3317446494475\n",
      "Epoch 274 / 1000 loss: 12.331741916015744\n",
      "Epoch 275 / 1000 loss: 12.331739180721343\n",
      "Epoch 276 / 1000 loss: 12.331736497581005\n",
      "Epoch 277 / 1000 loss: 12.33173385169357\n",
      "Epoch 278 / 1000 loss: 12.331731184385717\n",
      "Epoch 279 / 1000 loss: 12.331728478893638\n",
      "Epoch 280 / 1000 loss: 12.331725833937526\n",
      "Epoch 281 / 1000 loss: 12.331723189912736\n",
      "Epoch 282 / 1000 loss: 12.331720609217882\n",
      "Epoch 283 / 1000 loss: 12.33171788789332\n",
      "Epoch 284 / 1000 loss: 12.331715249456465\n",
      "Epoch 285 / 1000 loss: 12.331712725572288\n",
      "Epoch 286 / 1000 loss: 12.331709954887629\n",
      "Epoch 287 / 1000 loss: 12.33170734345913\n",
      "Epoch 288 / 1000 loss: 12.331704786978662\n",
      "Epoch 289 / 1000 loss: 12.331702106632292\n",
      "Epoch 290 / 1000 loss: 12.331699538044631\n",
      "Epoch 291 / 1000 loss: 12.331696923822165\n",
      "Epoch 292 / 1000 loss: 12.331694333814085\n",
      "Epoch 293 / 1000 loss: 12.33169171307236\n",
      "Epoch 294 / 1000 loss: 12.331689152866602\n",
      "Epoch 295 / 1000 loss: 12.331686652265489\n",
      "Epoch 296 / 1000 loss: 12.33168407715857\n",
      "Epoch 297 / 1000 loss: 12.331681518815458\n",
      "Epoch 298 / 1000 loss: 12.331678921356797\n",
      "Epoch 299 / 1000 loss: 12.331676394678652\n",
      "Epoch 300 / 1000 loss: 12.331673846580088\n",
      "Epoch 301 / 1000 loss: 12.331671189516783\n",
      "Epoch 302 / 1000 loss: 12.33166866749525\n",
      "Epoch 303 / 1000 loss: 12.331666197627783\n",
      "Epoch 304 / 1000 loss: 12.331663621589541\n",
      "Epoch 305 / 1000 loss: 12.331661056727171\n",
      "Epoch 306 / 1000 loss: 12.331658605486155\n",
      "Epoch 307 / 1000 loss: 12.331656104885042\n",
      "Epoch 308 / 1000 loss: 12.331653560511768\n",
      "Epoch 309 / 1000 loss: 12.331651018932462\n",
      "Epoch 310 / 1000 loss: 12.331648528575897\n",
      "Epoch 311 / 1000 loss: 12.33164600841701\n",
      "Epoch 312 / 1000 loss: 12.331643560901284\n",
      "Epoch 313 / 1000 loss: 12.331641096621752\n",
      "Epoch 314 / 1000 loss: 12.331638569943607\n",
      "Epoch 315 / 1000 loss: 12.331636073067784\n",
      "Epoch 316 / 1000 loss: 12.331633603200316\n",
      "Epoch 317 / 1000 loss: 12.331631137058139\n",
      "Epoch 318 / 1000 loss: 12.331628716550767\n",
      "Epoch 319 / 1000 loss: 12.331626331433654\n",
      "Epoch 320 / 1000 loss: 12.331623792648315\n",
      "Epoch 321 / 1000 loss: 12.331621374934912\n",
      "Epoch 322 / 1000 loss: 12.33161888923496\n",
      "Epoch 323 / 1000 loss: 12.331616459414363\n",
      "Epoch 324 / 1000 loss: 12.331613978371024\n",
      "Epoch 325 / 1000 loss: 12.331611542962492\n",
      "Epoch 326 / 1000 loss: 12.331609233282506\n",
      "Epoch 327 / 1000 loss: 12.331606723368168\n",
      "Epoch 328 / 1000 loss: 12.331604320555925\n",
      "Epoch 329 / 1000 loss: 12.331601904705167\n",
      "Epoch 330 / 1000 loss: 12.33159951493144\n",
      "Epoch 331 / 1000 loss: 12.331597153097391\n",
      "Epoch 332 / 1000 loss: 12.331594720482826\n",
      "Epoch 333 / 1000 loss: 12.331592315807939\n",
      "Epoch 334 / 1000 loss: 12.331589959561825\n",
      "Epoch 335 / 1000 loss: 12.331587607972324\n",
      "Epoch 336 / 1000 loss: 12.331585218198597\n",
      "Epoch 337 / 1000 loss: 12.331582833081484\n",
      "Epoch 338 / 1000 loss: 12.331580459140241\n",
      "Epoch 339 / 1000 loss: 12.331578041426837\n",
      "Epoch 340 / 1000 loss: 12.331575741060078\n",
      "Epoch 341 / 1000 loss: 12.331573392264545\n",
      "Epoch 342 / 1000 loss: 12.331570985727012\n",
      "Epoch 343 / 1000 loss: 12.331568623892963\n",
      "Epoch 344 / 1000 loss: 12.331566339358687\n",
      "Epoch 345 / 1000 loss: 12.331563966348767\n",
      "Epoch 346 / 1000 loss: 12.33156171720475\n",
      "Epoch 347 / 1000 loss: 12.331559396348894\n",
      "Epoch 348 / 1000 loss: 12.331556948833168\n",
      "Epoch 349 / 1000 loss: 12.331554694101214\n",
      "Epoch 350 / 1000 loss: 12.331552356481552\n",
      "Epoch 351 / 1000 loss: 12.331550101749599\n",
      "Epoch 352 / 1000 loss: 12.331547788344324\n",
      "Epoch 353 / 1000 loss: 12.331545422784984\n",
      "Epoch 354 / 1000 loss: 12.331543182954192\n",
      "Epoch 355 / 1000 loss: 12.331540926359594\n",
      "Epoch 356 / 1000 loss: 12.331538597121835\n",
      "Epoch 357 / 1000 loss: 12.331536321900785\n",
      "Epoch 358 / 1000 loss: 12.33153401594609\n",
      "Epoch 359 / 1000 loss: 12.33153175842017\n",
      "Epoch 360 / 1000 loss: 12.331529468297958\n",
      "Epoch 361 / 1000 loss: 12.331527213566005\n",
      "Epoch 362 / 1000 loss: 12.33152496535331\n",
      "Epoch 363 / 1000 loss: 12.33152269013226\n",
      "Epoch 364 / 1000 loss: 12.331520463339984\n",
      "Epoch 365 / 1000 loss: 12.331518228165805\n",
      "Epoch 366 / 1000 loss: 12.331515973433852\n",
      "Epoch 367 / 1000 loss: 12.331513711251318\n",
      "Epoch 368 / 1000 loss: 12.331511436961591\n",
      "Epoch 369 / 1000 loss: 12.331509187817574\n",
      "Epoch 370 / 1000 loss: 12.331506947055459\n",
      "Epoch 371 / 1000 loss: 12.331504749134183\n",
      "Epoch 372 / 1000 loss: 12.331502578221262\n",
      "Epoch 373 / 1000 loss: 12.331500336527824\n",
      "Epoch 374 / 1000 loss: 12.331498091109097\n",
      "Epoch 375 / 1000 loss: 12.331495933234692\n",
      "Epoch 376 / 1000 loss: 12.331493712030351\n",
      "Epoch 377 / 1000 loss: 12.331491509452462\n",
      "Epoch 378 / 1000 loss: 12.331489230506122\n",
      "Epoch 379 / 1000 loss: 12.331487128511071\n",
      "Epoch 380 / 1000 loss: 12.331484931521118\n",
      "Epoch 381 / 1000 loss: 12.331482725217938\n",
      "Epoch 382 / 1000 loss: 12.331480556167662\n",
      "Epoch 383 / 1000 loss: 12.331478429026902\n",
      "Epoch 384 / 1000 loss: 12.331476150080562\n",
      "Epoch 385 / 1000 loss: 12.331474018283188\n",
      "Epoch 386 / 1000 loss: 12.331471896730363\n",
      "Epoch 387 / 1000 loss: 12.33146969974041\n",
      "Epoch 388 / 1000 loss: 12.331467539072037\n",
      "Epoch 389 / 1000 loss: 12.331465352326632\n",
      "Epoch 390 / 1000 loss: 12.33146323915571\n",
      "Epoch 391 / 1000 loss: 12.331461100839078\n",
      "Epoch 392 / 1000 loss: 12.331458917818964\n",
      "Epoch 393 / 1000 loss: 12.331456751562655\n",
      "Epoch 394 / 1000 loss: 12.331454603001475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 395 / 1000 loss: 12.331452527083457\n",
      "Epoch 396 / 1000 loss: 12.331450434401631\n",
      "Epoch 397 / 1000 loss: 12.33144823089242\n",
      "Epoch 398 / 1000 loss: 12.331446154043078\n",
      "Epoch 399 / 1000 loss: 12.331444002687931\n",
      "Epoch 400 / 1000 loss: 12.331441896036267\n",
      "Epoch 401 / 1000 loss: 12.33143980242312\n",
      "Epoch 402 / 1000 loss: 12.33143768645823\n",
      "Epoch 403 / 1000 loss: 12.331435607746243\n",
      "Epoch 404 / 1000 loss: 12.33143351227045\n",
      "Epoch 405 / 1000 loss: 12.331431366503239\n",
      "Epoch 406 / 1000 loss: 12.331429310142994\n",
      "Epoch 407 / 1000 loss: 12.331427183933556\n",
      "Epoch 408 / 1000 loss: 12.331425098702312\n",
      "Epoch 409 / 1000 loss: 12.331423011608422\n",
      "Epoch 410 / 1000 loss: 12.331420983187854\n",
      "Epoch 411 / 1000 loss: 12.331418910995126\n",
      "Epoch 412 / 1000 loss: 12.331416849978268\n",
      "Epoch 413 / 1000 loss: 12.331414744257927\n",
      "Epoch 414 / 1000 loss: 12.331412645988166\n",
      "Epoch 415 / 1000 loss: 12.3314105598256\n",
      "Epoch 416 / 1000 loss: 12.331408558413386\n",
      "Epoch 417 / 1000 loss: 12.331406557001173\n",
      "Epoch 418 / 1000 loss: 12.331404498778284\n",
      "Epoch 419 / 1000 loss: 12.331402407027781\n",
      "Epoch 420 / 1000 loss: 12.331400369293988\n",
      "Epoch 421 / 1000 loss: 12.331398301757872\n",
      "Epoch 422 / 1000 loss: 12.331396374851465\n",
      "Epoch 423 / 1000 loss: 12.331394305452704\n",
      "Epoch 424 / 1000 loss: 12.33139227796346\n",
      "Epoch 425 / 1000 loss: 12.331390204839408\n",
      "Epoch 426 / 1000 loss: 12.33138816524297\n",
      "Epoch 427 / 1000 loss: 12.3313861573115\n",
      "Epoch 428 / 1000 loss: 12.331384137272835\n",
      "Epoch 429 / 1000 loss: 12.331382136791945\n",
      "Epoch 430 / 1000 loss: 12.331380119547248\n",
      "Epoch 431 / 1000 loss: 12.331378060393035\n",
      "Epoch 432 / 1000 loss: 12.331376110203564\n",
      "Epoch 433 / 1000 loss: 12.331374094821513\n",
      "Epoch 434 / 1000 loss: 12.331372125074267\n",
      "Epoch 435 / 1000 loss: 12.331370115280151\n",
      "Epoch 436 / 1000 loss: 12.331368163228035\n",
      "Epoch 437 / 1000 loss: 12.331366196274757\n",
      "Epoch 438 / 1000 loss: 12.3313641641289\n",
      "Epoch 439 / 1000 loss: 12.331362183205783\n",
      "Epoch 440 / 1000 loss: 12.331360182724893\n",
      "Epoch 441 / 1000 loss: 12.331358186900616\n",
      "Epoch 442 / 1000 loss: 12.331356273032725\n",
      "Epoch 443 / 1000 loss: 12.331354277208447\n",
      "Epoch 444 / 1000 loss: 12.331352325156331\n",
      "Epoch 445 / 1000 loss: 12.331350332126021\n",
      "Epoch 446 / 1000 loss: 12.331348449923098\n",
      "Epoch 447 / 1000 loss: 12.331346404738724\n",
      "Epoch 448 / 1000 loss: 12.331344522535801\n",
      "Epoch 449 / 1000 loss: 12.331342524848878\n",
      "Epoch 450 / 1000 loss: 12.331340603530407\n",
      "Epoch 451 / 1000 loss: 12.331338737159967\n",
      "Epoch 452 / 1000 loss: 12.331336732022464\n",
      "Epoch 453 / 1000 loss: 12.331334766931832\n",
      "Epoch 454 / 1000 loss: 12.331332842819393\n",
      "Epoch 455 / 1000 loss: 12.331330959685147\n",
      "Epoch 456 / 1000 loss: 12.331329033710063\n",
      "Epoch 457 / 1000 loss: 12.331327112391591\n",
      "Epoch 458 / 1000 loss: 12.331325168721378\n",
      "Epoch 459 / 1000 loss: 12.331323298625648\n",
      "Epoch 460 / 1000 loss: 12.33132133167237\n",
      "Epoch 461 / 1000 loss: 12.33131942898035\n",
      "Epoch 462 / 1000 loss: 12.331317479722202\n",
      "Epoch 463 / 1000 loss: 12.33131561614573\n",
      "Epoch 464 / 1000 loss: 12.33131373859942\n",
      "Epoch 465 / 1000 loss: 12.3313118359074\n",
      "Epoch 466 / 1000 loss: 12.33130994439125\n",
      "Epoch 467 / 1000 loss: 12.33130808826536\n",
      "Epoch 468 / 1000 loss: 12.331306148320436\n",
      "Epoch 469 / 1000 loss: 12.331304266117513\n",
      "Epoch 470 / 1000 loss: 12.331302342936397\n",
      "Epoch 471 / 1000 loss: 12.331300505436957\n",
      "Epoch 472 / 1000 loss: 12.331298653967679\n",
      "Epoch 473 / 1000 loss: 12.331296801567078\n",
      "Epoch 474 / 1000 loss: 12.331294906325638\n",
      "Epoch 475 / 1000 loss: 12.331293049268425\n",
      "Epoch 476 / 1000 loss: 12.33129117731005\n",
      "Epoch 477 / 1000 loss: 12.331289276480675\n",
      "Epoch 478 / 1000 loss: 12.33128746598959\n",
      "Epoch 479 / 1000 loss: 12.331285567954183\n",
      "Epoch 480 / 1000 loss: 12.331283686682582\n",
      "Epoch 481 / 1000 loss: 12.331281839869916\n",
      "Epoch 482 / 1000 loss: 12.331280089914799\n",
      "Epoch 483 / 1000 loss: 12.33127813320607\n",
      "Epoch 484 / 1000 loss: 12.331276312470436\n",
      "Epoch 485 / 1000 loss: 12.331274481490254\n",
      "Epoch 486 / 1000 loss: 12.331272596493363\n",
      "Epoch 487 / 1000 loss: 12.33127084840089\n",
      "Epoch 488 / 1000 loss: 12.331268949434161\n",
      "Epoch 489 / 1000 loss: 12.33126718364656\n",
      "Epoch 490 / 1000 loss: 12.331265304237604\n",
      "Epoch 491 / 1000 loss: 12.331263469532132\n",
      "Epoch 492 / 1000 loss: 12.331261655315757\n",
      "Epoch 493 / 1000 loss: 12.331259794533253\n",
      "Epoch 494 / 1000 loss: 12.331258083693683\n",
      "Epoch 495 / 1000 loss: 12.33125628810376\n",
      "Epoch 496 / 1000 loss: 12.331254462711513\n",
      "Epoch 497 / 1000 loss: 12.331252595409751\n",
      "Epoch 498 / 1000 loss: 12.331250824965537\n",
      "Epoch 499 / 1000 loss: 12.331249013543129\n",
      "Epoch 500 / 1000 loss: 12.331247192807496\n",
      "Epoch 501 / 1000 loss: 12.331245452165604\n",
      "Epoch 502 / 1000 loss: 12.331243569031358\n",
      "Epoch 503 / 1000 loss: 12.331241829320788\n",
      "Epoch 504 / 1000 loss: 12.331240009516478\n",
      "Epoch 505 / 1000 loss: 12.331238262355328\n",
      "Epoch 506 / 1000 loss: 12.331236471422017\n",
      "Epoch 507 / 1000 loss: 12.33123473264277\n",
      "Epoch 508 / 1000 loss: 12.331232917495072\n",
      "Epoch 509 / 1000 loss: 12.331231096759439\n",
      "Epoch 510 / 1000 loss: 12.33122939709574\n",
      "Epoch 511 / 1000 loss: 12.331227631308138\n",
      "Epoch 512 / 1000 loss: 12.331225824542344\n",
      "Epoch 513 / 1000 loss: 12.331224082969129\n",
      "Epoch 514 / 1000 loss: 12.331222355365753\n",
      "Epoch 515 / 1000 loss: 12.331220512278378\n",
      "Epoch 516 / 1000 loss: 12.331218672916293\n",
      "Epoch 517 / 1000 loss: 12.331216995604336\n",
      "Epoch 518 / 1000 loss: 12.331215216778219\n",
      "Epoch 519 / 1000 loss: 12.331213515251875\n",
      "Epoch 520 / 1000 loss: 12.331211796961725\n",
      "Epoch 521 / 1000 loss: 12.33121005166322\n",
      "Epoch 522 / 1000 loss: 12.331208327785134\n",
      "Epoch 523 / 1000 loss: 12.331206603907049\n",
      "Epoch 524 / 1000 loss: 12.331204836256802\n",
      "Epoch 525 / 1000 loss: 12.331203154288232\n",
      "Epoch 526 / 1000 loss: 12.33120133727789\n",
      "Epoch 527 / 1000 loss: 12.331199667416513\n",
      "Epoch 528 / 1000 loss: 12.331197974272072\n",
      "Epoch 529 / 1000 loss: 12.331196152605116\n",
      "Epoch 530 / 1000 loss: 12.331194559112191\n",
      "Epoch 531 / 1000 loss: 12.331192840822041\n",
      "Epoch 532 / 1000 loss: 12.331191022880375\n",
      "Epoch 533 / 1000 loss: 12.331189397722483\n",
      "Epoch 534 / 1000 loss: 12.331187621690333\n",
      "Epoch 535 / 1000 loss: 12.33118594251573\n",
      "Epoch 536 / 1000 loss: 12.331184227950871\n",
      "Epoch 537 / 1000 loss: 12.331182511523366\n",
      "Epoch 538 / 1000 loss: 12.331180763430893\n",
      "Epoch 539 / 1000 loss: 12.331179008819163\n",
      "Epoch 540 / 1000 loss: 12.33117740508169\n",
      "Epoch 541 / 1000 loss: 12.331175680272281\n",
      "Epoch 542 / 1000 loss: 12.331174003891647\n",
      "Epoch 543 / 1000 loss: 12.33117233775556\n",
      "Epoch 544 / 1000 loss: 12.331170668825507\n",
      "Epoch 545 / 1000 loss: 12.331169006414711\n",
      "Epoch 546 / 1000 loss: 12.331167348660529\n",
      "Epoch 547 / 1000 loss: 12.331165650859475\n",
      "Epoch 548 / 1000 loss: 12.331163948401809\n",
      "Epoch 549 / 1000 loss: 12.331162297166884\n",
      "Epoch 550 / 1000 loss: 12.331160611473024\n",
      "Epoch 551 / 1000 loss: 12.331158985383809\n",
      "Epoch 552 / 1000 loss: 12.331157300621271\n",
      "Epoch 553 / 1000 loss: 12.331155615858734\n",
      "Epoch 554 / 1000 loss: 12.33115394692868\n",
      "Epoch 555 / 1000 loss: 12.331152306869626\n",
      "Epoch 556 / 1000 loss: 12.331150551326573\n",
      "Epoch 557 / 1000 loss: 12.331149009987712\n",
      "Epoch 558 / 1000 loss: 12.331147291697562\n",
      "Epoch 559 / 1000 loss: 12.331145626492798\n",
      "Epoch 560 / 1000 loss: 12.331143962219357\n",
      "Epoch 561 / 1000 loss: 12.331142402254045\n",
      "Epoch 562 / 1000 loss: 12.331140731461346\n",
      "Epoch 563 / 1000 loss: 12.331139083951712\n",
      "Epoch 564 / 1000 loss: 12.331137468107045\n",
      "Epoch 565 / 1000 loss: 12.331135897897184\n",
      "Epoch 566 / 1000 loss: 12.331134165637195\n",
      "Epoch 567 / 1000 loss: 12.33113248925656\n",
      "Epoch 568 / 1000 loss: 12.331130838952959\n",
      "Epoch 569 / 1000 loss: 12.331129305064678\n",
      "Epoch 570 / 1000 loss: 12.331127665936947\n",
      "Epoch 571 / 1000 loss: 12.331126002594829\n",
      "Epoch 572 / 1000 loss: 12.331124376505613\n",
      "Epoch 573 / 1000 loss: 12.331122793257236\n",
      "Epoch 574 / 1000 loss: 12.331121203489602\n",
      "Epoch 575 / 1000 loss: 12.33111958950758\n",
      "Epoch 576 / 1000 loss: 12.331117962487042\n",
      "Epoch 577 / 1000 loss: 12.331116389483213\n",
      "Epoch 578 / 1000 loss: 12.331114784814417\n",
      "Epoch 579 / 1000 loss: 12.331113153137267\n",
      "Epoch 580 / 1000 loss: 12.331111580133438\n",
      "Epoch 581 / 1000 loss: 12.331109957769513\n",
      "Epoch 582 / 1000 loss: 12.33110838290304\n",
      "Epoch 583 / 1000 loss: 12.331106749363244\n",
      "Epoch 584 / 1000 loss: 12.331105107441545\n",
      "Epoch 585 / 1000 loss: 12.331103585660458\n",
      "Epoch 586 / 1000 loss: 12.331101970747113\n",
      "Epoch 587 / 1000 loss: 12.331100386567414\n",
      "Epoch 588 / 1000 loss: 12.331098832190037\n",
      "Epoch 589 / 1000 loss: 12.331097246147692\n",
      "Epoch 590 / 1000 loss: 12.331095690838993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 591 / 1000 loss: 12.331094035878778\n",
      "Epoch 592 / 1000 loss: 12.33109251409769\n",
      "Epoch 593 / 1000 loss: 12.331090923398733\n",
      "Epoch 594 / 1000 loss: 12.331089299172163\n",
      "Epoch 595 / 1000 loss: 12.331087766215205\n",
      "Epoch 596 / 1000 loss: 12.331086214631796\n",
      "Epoch 597 / 1000 loss: 12.331084701232612\n",
      "Epoch 598 / 1000 loss: 12.331083100289106\n",
      "Epoch 599 / 1000 loss: 12.331081498414278\n",
      "Epoch 600 / 1000 loss: 12.331079999916255\n",
      "Epoch 601 / 1000 loss: 12.331078426912427\n",
      "Epoch 602 / 1000 loss: 12.331076830625534\n",
      "Epoch 603 / 1000 loss: 12.331075308844447\n",
      "Epoch 604 / 1000 loss: 12.331073748879135\n",
      "Epoch 605 / 1000 loss: 12.331072181463242\n",
      "Epoch 606 / 1000 loss: 12.331070684827864\n",
      "Epoch 607 / 1000 loss: 12.331069159321487\n",
      "Epoch 608 / 1000 loss: 12.331067587248981\n",
      "Epoch 609 / 1000 loss: 12.331066023558378\n",
      "Epoch 610 / 1000 loss: 12.331064464524388\n",
      "Epoch 611 / 1000 loss: 12.331062991172075\n",
      "Epoch 612 / 1000 loss: 12.331061429344118\n",
      "Epoch 613 / 1000 loss: 12.331059934571385\n",
      "Epoch 614 / 1000 loss: 12.331058343872428\n",
      "Epoch 615 / 1000 loss: 12.331056837923825\n",
      "Epoch 616 / 1000 loss: 12.33105532079935\n",
      "Epoch 617 / 1000 loss: 12.33105378691107\n",
      "Epoch 618 / 1000 loss: 12.331052268855274\n",
      "Epoch 619 / 1000 loss: 12.331050712615252\n",
      "Epoch 620 / 1000 loss: 12.33104925788939\n",
      "Epoch 621 / 1000 loss: 12.331047642976046\n",
      "Epoch 622 / 1000 loss: 12.33104619011283\n",
      "Epoch 623 / 1000 loss: 12.331044632010162\n",
      "Epoch 624 / 1000 loss: 12.331043139100075\n",
      "Epoch 625 / 1000 loss: 12.331041640602052\n",
      "Epoch 626 / 1000 loss: 12.331040152348578\n",
      "Epoch 627 / 1000 loss: 12.33103871718049\n",
      "Epoch 628 / 1000 loss: 12.331037072464824\n",
      "Epoch 629 / 1000 loss: 12.331035651266575\n",
      "Epoch 630 / 1000 loss: 12.331034140661359\n",
      "Epoch 631 / 1000 loss: 12.331032741814852\n",
      "Epoch 632 / 1000 loss: 12.331031170673668\n",
      "Epoch 633 / 1000 loss: 12.331029652617872\n",
      "Epoch 634 / 1000 loss: 12.331028134562075\n",
      "Epoch 635 / 1000 loss: 12.331026659347117\n",
      "Epoch 636 / 1000 loss: 12.331025200895965\n",
      "Epoch 637 / 1000 loss: 12.33102366514504\n",
      "Epoch 638 / 1000 loss: 12.331022216007113\n",
      "Epoch 639 / 1000 loss: 12.331020729616284\n",
      "Epoch 640 / 1000 loss: 12.331019287928939\n",
      "Epoch 641 / 1000 loss: 12.331017762422562\n",
      "Epoch 642 / 1000 loss: 12.331016284413636\n",
      "Epoch 643 / 1000 loss: 12.331014832481742\n",
      "Epoch 644 / 1000 loss: 12.331013400107622\n",
      "Epoch 645 / 1000 loss: 12.331011983565986\n",
      "Epoch 646 / 1000 loss: 12.331010391004384\n",
      "Epoch 647 / 1000 loss: 12.331008985638618\n",
      "Epoch 648 / 1000 loss: 12.331007563509047\n",
      "Epoch 649 / 1000 loss: 12.331006109714508\n",
      "Epoch 650 / 1000 loss: 12.331004570238292\n",
      "Epoch 651 / 1000 loss: 12.331003220751882\n",
      "Epoch 652 / 1000 loss: 12.331001716665924\n",
      "Epoch 653 / 1000 loss: 12.331000285223126\n",
      "Epoch 654 / 1000 loss: 12.330998769029975\n",
      "Epoch 655 / 1000 loss: 12.330997311510146\n",
      "Epoch 656 / 1000 loss: 12.330995883792639\n",
      "Epoch 657 / 1000 loss: 12.330994403921068\n",
      "Epoch 658 / 1000 loss: 12.330992963165045\n",
      "Epoch 659 / 1000 loss: 12.330991530790925\n",
      "Epoch 660 / 1000 loss: 12.33099009655416\n",
      "Epoch 661 / 1000 loss: 12.330988704226911\n",
      "Epoch 662 / 1000 loss: 12.33098735846579\n",
      "Epoch 663 / 1000 loss: 12.330985803157091\n",
      "Epoch 664 / 1000 loss: 12.330984305590391\n",
      "Epoch 665 / 1000 loss: 12.330982974730432\n",
      "Epoch 666 / 1000 loss: 12.330981496721506\n",
      "Epoch 667 / 1000 loss: 12.330980057828128\n",
      "Epoch 668 / 1000 loss: 12.33097867295146\n",
      "Epoch 669 / 1000 loss: 12.330977220088243\n",
      "Epoch 670 / 1000 loss: 12.330975752323866\n",
      "Epoch 671 / 1000 loss: 12.330974319949746\n",
      "Epoch 672 / 1000 loss: 12.330972994677722\n",
      "Epoch 673 / 1000 loss: 12.330971495248377\n",
      "Epoch 674 / 1000 loss: 12.330970097333193\n",
      "Epoch 675 / 1000 loss: 12.330968703143299\n",
      "Epoch 676 / 1000 loss: 12.330967259593308\n",
      "Epoch 677 / 1000 loss: 12.330965880304575\n",
      "Epoch 678 / 1000 loss: 12.330964498221874\n",
      "Epoch 679 / 1000 loss: 12.330963086336851\n",
      "Epoch 680 / 1000 loss: 12.330961616709828\n",
      "Epoch 681 / 1000 loss: 12.330960245802999\n",
      "Epoch 682 / 1000 loss: 12.330958847887814\n",
      "Epoch 683 / 1000 loss: 12.33095747884363\n",
      "Epoch 684 / 1000 loss: 12.33095609024167\n",
      "Epoch 685 / 1000 loss: 12.330954619683325\n",
      "Epoch 686 / 1000 loss: 12.330953307449818\n",
      "Epoch 687 / 1000 loss: 12.330951852723956\n",
      "Epoch 688 / 1000 loss: 12.33095043245703\n",
      "Epoch 689 / 1000 loss: 12.330949080176651\n",
      "Epoch 690 / 1000 loss: 12.33094774093479\n",
      "Epoch 691 / 1000 loss: 12.330946245230734\n",
      "Epoch 692 / 1000 loss: 12.330944927409291\n",
      "Epoch 693 / 1000 loss: 12.330943552777171\n",
      "Epoch 694 / 1000 loss: 12.330942220054567\n",
      "Epoch 695 / 1000 loss: 12.330940740182996\n",
      "Epoch 696 / 1000 loss: 12.330939364619553\n",
      "Epoch 697 / 1000 loss: 12.330937949940562\n",
      "Epoch 698 / 1000 loss: 12.330936646088958\n",
      "Epoch 699 / 1000 loss: 12.330935253761709\n",
      "Epoch 700 / 1000 loss: 12.330933952704072\n",
      "Epoch 701 / 1000 loss: 12.330932491458952\n",
      "Epoch 702 / 1000 loss: 12.330931165255606\n",
      "Epoch 703 / 1000 loss: 12.330929778516293\n",
      "Epoch 704 / 1000 loss: 12.33092838153243\n",
      "Epoch 705 / 1000 loss: 12.330927056260407\n",
      "Epoch 706 / 1000 loss: 12.33092566858977\n",
      "Epoch 707 / 1000 loss: 12.330924297682941\n",
      "Epoch 708 / 1000 loss: 12.330923008732498\n",
      "Epoch 709 / 1000 loss: 12.330921626649797\n",
      "Epoch 710 / 1000 loss: 12.330920291133225\n",
      "Epoch 711 / 1000 loss: 12.330918906256557\n",
      "Epoch 712 / 1000 loss: 12.330917649902403\n",
      "Epoch 713 / 1000 loss: 12.330916224978864\n",
      "Epoch 714 / 1000 loss: 12.330914811231196\n",
      "Epoch 715 / 1000 loss: 12.330913466401398\n",
      "Epoch 716 / 1000 loss: 12.33091218303889\n",
      "Epoch 717 / 1000 loss: 12.330910736694932\n",
      "Epoch 718 / 1000 loss: 12.33090942632407\n",
      "Epoch 719 / 1000 loss: 12.330908125266433\n",
      "Epoch 720 / 1000 loss: 12.330906819552183\n",
      "Epoch 721 / 1000 loss: 12.330905536189675\n",
      "Epoch 722 / 1000 loss: 12.330904141068459\n",
      "Epoch 723 / 1000 loss: 12.330902844667435\n",
      "Epoch 724 / 1000 loss: 12.330901486799121\n",
      "Epoch 725 / 1000 loss: 12.330900190398097\n",
      "Epoch 726 / 1000 loss: 12.330898732878268\n",
      "Epoch 727 / 1000 loss: 12.330897546373308\n",
      "Epoch 728 / 1000 loss: 12.330896073020995\n",
      "Epoch 729 / 1000 loss: 12.330894844606519\n",
      "Epoch 730 / 1000 loss: 12.33089351374656\n",
      "Epoch 731 / 1000 loss: 12.330892165191472\n",
      "Epoch 732 / 1000 loss: 12.33089086972177\n",
      "Epoch 733 / 1000 loss: 12.330889576114714\n",
      "Epoch 734 / 1000 loss: 12.330888195894659\n",
      "Epoch 735 / 1000 loss: 12.330886914394796\n",
      "Epoch 736 / 1000 loss: 12.330885618925095\n",
      "Epoch 737 / 1000 loss: 12.330884291790426\n",
      "Epoch 738 / 1000 loss: 12.330882951617241\n",
      "Epoch 739 / 1000 loss: 12.330881650559604\n",
      "Epoch 740 / 1000 loss: 12.330880302004516\n",
      "Epoch 741 / 1000 loss: 12.330879076384008\n",
      "Epoch 742 / 1000 loss: 12.330877741798759\n",
      "Epoch 743 / 1000 loss: 12.330876424908638\n",
      "Epoch 744 / 1000 loss: 12.330875135026872\n",
      "Epoch 745 / 1000 loss: 12.330873813480139\n",
      "Epoch 746 / 1000 loss: 12.330872485414147\n",
      "Epoch 747 / 1000 loss: 12.330871270038188\n",
      "Epoch 748 / 1000 loss: 12.330869883298874\n",
      "Epoch 749 / 1000 loss: 12.330868643708527\n",
      "Epoch 750 / 1000 loss: 12.330867357552052\n",
      "Epoch 751 / 1000 loss: 12.330866086296737\n",
      "Epoch 752 / 1000 loss: 12.330864760093391\n",
      "Epoch 753 / 1000 loss: 12.330863490700722\n",
      "Epoch 754 / 1000 loss: 12.330862179398537\n",
      "Epoch 755 / 1000 loss: 12.330860920250416\n",
      "Epoch 756 / 1000 loss: 12.33085959404707\n",
      "Epoch 757 / 1000 loss: 12.3308584401384\n",
      "Epoch 758 / 1000 loss: 12.33085709810257\n",
      "Epoch 759 / 1000 loss: 12.33085582125932\n",
      "Epoch 760 / 1000 loss: 12.330854528583586\n",
      "Epoch 761 / 1000 loss: 12.330853243358433\n",
      "Epoch 762 / 1000 loss: 12.330851980485022\n",
      "Epoch 763 / 1000 loss: 12.330850729718804\n",
      "Epoch 764 / 1000 loss: 12.33084944728762\n",
      "Epoch 765 / 1000 loss: 12.330848191864789\n",
      "Epoch 766 / 1000 loss: 12.330846881493926\n",
      "Epoch 767 / 1000 loss: 12.330845667049289\n",
      "Epoch 768 / 1000 loss: 12.330844335258007\n",
      "Epoch 769 / 1000 loss: 12.33084306679666\n",
      "Epoch 770 / 1000 loss: 12.330841835588217\n",
      "Epoch 771 / 1000 loss: 12.330840558744967\n",
      "Epoch 772 / 1000 loss: 12.330839251168072\n",
      "Epoch 773 / 1000 loss: 12.330837986432016\n",
      "Epoch 774 / 1000 loss: 12.330836816690862\n",
      "Epoch 775 / 1000 loss: 12.330835532397032\n",
      "Epoch 776 / 1000 loss: 12.330834337510169\n",
      "Epoch 777 / 1000 loss: 12.330833040177822\n",
      "Epoch 778 / 1000 loss: 12.330831786617637\n",
      "Epoch 779 / 1000 loss: 12.330830513499677\n",
      "Epoch 780 / 1000 loss: 12.330829286016524\n",
      "Epoch 781 / 1000 loss: 12.3308279896155\n",
      "Epoch 782 / 1000 loss: 12.330826778896153\n",
      "Epoch 783 / 1000 loss: 12.330825523473322\n",
      "Epoch 784 / 1000 loss: 12.330824306234717\n",
      "Epoch 785 / 1000 loss: 12.330823029391468\n",
      "Epoch 786 / 1000 loss: 12.330821751616895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 787 / 1000 loss: 12.330820572562516\n",
      "Epoch 788 / 1000 loss: 12.33081931527704\n",
      "Epoch 789 / 1000 loss: 12.330818091519177\n",
      "Epoch 790 / 1000 loss: 12.330816849134862\n",
      "Epoch 791 / 1000 loss: 12.330815584398806\n",
      "Epoch 792 / 1000 loss: 12.3308143960312\n",
      "Epoch 793 / 1000 loss: 12.330813214182854\n",
      "Epoch 794 / 1000 loss: 12.33081188146025\n",
      "Epoch 795 / 1000 loss: 12.330810667946935\n",
      "Epoch 796 / 1000 loss: 12.3308094907552\n",
      "Epoch 797 / 1000 loss: 12.330808224156499\n",
      "Epoch 798 / 1000 loss: 12.330806982703507\n",
      "Epoch 799 / 1000 loss: 12.330805771052837\n",
      "Epoch 800 / 1000 loss: 12.330804543569684\n",
      "Epoch 801 / 1000 loss: 12.330803408287466\n",
      "Epoch 802 / 1000 loss: 12.330802148208022\n",
      "Epoch 803 / 1000 loss: 12.330800953321159\n",
      "Epoch 804 / 1000 loss: 12.330799766816199\n",
      "Epoch 805 / 1000 loss: 12.33079849369824\n",
      "Epoch 806 / 1000 loss: 12.330797313712537\n",
      "Epoch 807 / 1000 loss: 12.330796067602932\n",
      "Epoch 808 / 1000 loss: 12.330794866196811\n",
      "Epoch 809 / 1000 loss: 12.330793590284884\n",
      "Epoch 810 / 1000 loss: 12.33079238049686\n",
      "Epoch 811 / 1000 loss: 12.33079119771719\n",
      "Epoch 812 / 1000 loss: 12.3307900512591\n",
      "Epoch 813 / 1000 loss: 12.330788773484528\n",
      "Epoch 814 / 1000 loss: 12.330787596292794\n",
      "Epoch 815 / 1000 loss: 12.33078642655164\n",
      "Epoch 816 / 1000 loss: 12.330785158090293\n",
      "Epoch 817 / 1000 loss: 12.33078399952501\n",
      "Epoch 818 / 1000 loss: 12.330782879143953\n",
      "Epoch 819 / 1000 loss: 12.33078165911138\n",
      "Epoch 820 / 1000 loss: 12.330780375748873\n",
      "Epoch 821 / 1000 loss: 12.330779223702848\n",
      "Epoch 822 / 1000 loss: 12.330778012983501\n",
      "Epoch 823 / 1000 loss: 12.33077681902796\n",
      "Epoch 824 / 1000 loss: 12.330775618553162\n",
      "Epoch 825 / 1000 loss: 12.330774443224072\n",
      "Epoch 826 / 1000 loss: 12.330773336812854\n",
      "Epoch 827 / 1000 loss: 12.330772079527378\n",
      "Epoch 828 / 1000 loss: 12.330770935863256\n",
      "Epoch 829 / 1000 loss: 12.33076972514391\n",
      "Epoch 830 / 1000 loss: 12.330768592655659\n",
      "Epoch 831 / 1000 loss: 12.330767400562763\n",
      "Epoch 832 / 1000 loss: 12.330766235478222\n",
      "Epoch 833 / 1000 loss: 12.330764998681843\n",
      "Epoch 834 / 1000 loss: 12.330763812176883\n",
      "Epoch 835 / 1000 loss: 12.330762716010213\n",
      "Epoch 836 / 1000 loss: 12.330761471763253\n",
      "Epoch 837 / 1000 loss: 12.330760275945067\n",
      "Epoch 838 / 1000 loss: 12.330759137868881\n",
      "Epoch 839 / 1000 loss: 12.330757917836308\n",
      "Epoch 840 / 1000 loss: 12.330756845884025\n",
      "Epoch 841 / 1000 loss: 12.330755649134517\n",
      "Epoch 842 / 1000 loss: 12.330754504539073\n",
      "Epoch 843 / 1000 loss: 12.330753269605339\n",
      "Epoch 844 / 1000 loss: 12.330752110108733\n",
      "Epoch 845 / 1000 loss: 12.330751039087772\n",
      "Epoch 846 / 1000 loss: 12.330749802291393\n",
      "Epoch 847 / 1000 loss: 12.330748623237014\n",
      "Epoch 848 / 1000 loss: 12.33074751496315\n",
      "Epoch 849 / 1000 loss: 12.330746391788125\n",
      "Epoch 850 / 1000 loss: 12.330745201557875\n",
      "Epoch 851 / 1000 loss: 12.330744043923914\n",
      "Epoch 852 / 1000 loss: 12.330742946825922\n",
      "Epoch 853 / 1000 loss: 12.330741731449962\n",
      "Epoch 854 / 1000 loss: 12.330740538425744\n",
      "Epoch 855 / 1000 loss: 12.330739435739815\n",
      "Epoch 856 / 1000 loss: 12.33073824737221\n",
      "Epoch 857 / 1000 loss: 12.33073712605983\n",
      "Epoch 858 / 1000 loss: 12.33073596097529\n",
      "Epoch 859 / 1000 loss: 12.330734870396554\n",
      "Epoch 860 / 1000 loss: 12.330733709037304\n",
      "Epoch 861 / 1000 loss: 12.330732556059957\n",
      "Epoch 862 / 1000 loss: 12.330731451511383\n",
      "Epoch 863 / 1000 loss: 12.330730274319649\n",
      "Epoch 864 / 1000 loss: 12.330729194916785\n",
      "Epoch 865 / 1000 loss: 12.330727983266115\n",
      "Epoch 866 / 1000 loss: 12.330726902000606\n",
      "Epoch 867 / 1000 loss: 12.330725741572678\n",
      "Epoch 868 / 1000 loss: 12.33072463888675\n",
      "Epoch 869 / 1000 loss: 12.330723414197564\n",
      "Epoch 870 / 1000 loss: 12.330722318962216\n",
      "Epoch 871 / 1000 loss: 12.330721138976514\n",
      "Epoch 872 / 1000 loss: 12.330720045603812\n",
      "Epoch 873 / 1000 loss: 12.33071895968169\n",
      "Epoch 874 / 1000 loss: 12.33071780577302\n",
      "Epoch 875 / 1000 loss: 12.330716642551124\n",
      "Epoch 876 / 1000 loss: 12.33071553800255\n",
      "Epoch 877 / 1000 loss: 12.330714437179267\n",
      "Epoch 878 / 1000 loss: 12.330713304691017\n",
      "Epoch 879 / 1000 loss: 12.330712183378637\n",
      "Epoch 880 / 1000 loss: 12.330711023882031\n",
      "Epoch 881 / 1000 loss: 12.330709907226264\n",
      "Epoch 882 / 1000 loss: 12.330708818510175\n",
      "Epoch 883 / 1000 loss: 12.330707693472505\n",
      "Epoch 884 / 1000 loss: 12.330706567503512\n",
      "Epoch 885 / 1000 loss: 12.330705501139164\n",
      "Epoch 886 / 1000 loss: 12.330704401247203\n",
      "Epoch 887 / 1000 loss: 12.330703236162663\n",
      "Epoch 888 / 1000 loss: 12.33070207387209\n",
      "Epoch 889 / 1000 loss: 12.330700994469225\n",
      "Epoch 890 / 1000 loss: 12.330699931830168\n",
      "Epoch 891 / 1000 loss: 12.33069877885282\n",
      "Epoch 892 / 1000 loss: 12.330697687342763\n",
      "Epoch 893 / 1000 loss: 12.330696595832705\n",
      "Epoch 894 / 1000 loss: 12.330695427022874\n",
      "Epoch 895 / 1000 loss: 12.330694428645074\n",
      "Epoch 896 / 1000 loss: 12.330693260766566\n",
      "Epoch 897 / 1000 loss: 12.330692118033767\n",
      "Epoch 898 / 1000 loss: 12.330691035836935\n",
      "Epoch 899 / 1000 loss: 12.330689962022007\n",
      "Epoch 900 / 1000 loss: 12.33068879880011\n",
      "Epoch 901 / 1000 loss: 12.330687724985182\n",
      "Epoch 902 / 1000 loss: 12.33068672567606\n",
      "Epoch 903 / 1000 loss: 12.330685614608228\n",
      "Epoch 904 / 1000 loss: 12.330684451386333\n",
      "Epoch 905 / 1000 loss: 12.33068335801363\n",
      "Epoch 906 / 1000 loss: 12.33068232331425\n",
      "Epoch 907 / 1000 loss: 12.330681226216257\n",
      "Epoch 908 / 1000 loss: 12.330680101178586\n",
      "Epoch 909 / 1000 loss: 12.330679059959948\n",
      "Epoch 910 / 1000 loss: 12.330677909776568\n",
      "Epoch 911 / 1000 loss: 12.330676928162575\n",
      "Epoch 912 / 1000 loss: 12.330675735138357\n",
      "Epoch 913 / 1000 loss: 12.330674686469138\n",
      "Epoch 914 / 1000 loss: 12.330673574469984\n",
      "Epoch 915 / 1000 loss: 12.330672500655055\n",
      "Epoch 916 / 1000 loss: 12.330671470612288\n",
      "Epoch 917 / 1000 loss: 12.330670380964875\n",
      "Epoch 918 / 1000 loss: 12.33066929411143\n",
      "Epoch 919 / 1000 loss: 12.330668177455664\n",
      "Epoch 920 / 1000 loss: 12.33066719584167\n",
      "Epoch 921 / 1000 loss: 12.330666031688452\n",
      "Epoch 922 / 1000 loss: 12.33066500350833\n",
      "Epoch 923 / 1000 loss: 12.330663874745369\n",
      "Epoch 924 / 1000 loss: 12.330662810243666\n",
      "Epoch 925 / 1000 loss: 12.330661793239415\n",
      "Epoch 926 / 1000 loss: 12.330660736188293\n",
      "Epoch 927 / 1000 loss: 12.330659707076848\n",
      "Epoch 928 / 1000 loss: 12.330658552236855\n",
      "Epoch 929 / 1000 loss: 12.33065748307854\n",
      "Epoch 930 / 1000 loss: 12.33065642695874\n",
      "Epoch 931 / 1000 loss: 12.33065539970994\n",
      "Epoch 932 / 1000 loss: 12.330654294230044\n",
      "Epoch 933 / 1000 loss: 12.330653215758502\n",
      "Epoch 934 / 1000 loss: 12.330652261152864\n",
      "Epoch 935 / 1000 loss: 12.330651124008\n",
      "Epoch 936 / 1000 loss: 12.33065012935549\n",
      "Epoch 937 / 1000 loss: 12.330649007111788\n",
      "Epoch 938 / 1000 loss: 12.330647947266698\n",
      "Epoch 939 / 1000 loss: 12.330646898597479\n",
      "Epoch 940 / 1000 loss: 12.330645791254938\n",
      "Epoch 941 / 1000 loss: 12.330644765868783\n",
      "Epoch 942 / 1000 loss: 12.33064373768866\n",
      "Epoch 943 / 1000 loss: 12.330642639659345\n",
      "Epoch 944 / 1000 loss: 12.330641647800803\n",
      "Epoch 945 / 1000 loss: 12.33064057212323\n",
      "Epoch 946 / 1000 loss: 12.330639509484172\n",
      "Epoch 947 / 1000 loss: 12.330638499930501\n",
      "Epoch 948 / 1000 loss: 12.330637389793992\n",
      "Epoch 949 / 1000 loss: 12.330636444501579\n",
      "Epoch 950 / 1000 loss: 12.330635381862521\n",
      "Epoch 951 / 1000 loss: 12.330634266138077\n",
      "Epoch 952 / 1000 loss: 12.330633228644729\n",
      "Epoch 953 / 1000 loss: 12.33063222374767\n",
      "Epoch 954 / 1000 loss: 12.330631154589355\n",
      "Epoch 955 / 1000 loss: 12.330630145035684\n",
      "Epoch 956 / 1000 loss: 12.330629087984562\n",
      "Epoch 957 / 1000 loss: 12.330628097988665\n",
      "Epoch 958 / 1000 loss: 12.330627052113414\n",
      "Epoch 959 / 1000 loss: 12.330625999718904\n",
      "Epoch 960 / 1000 loss: 12.330624944530427\n",
      "Epoch 961 / 1000 loss: 12.33062388189137\n",
      "Epoch 962 / 1000 loss: 12.3306228434667\n",
      "Epoch 963 / 1000 loss: 12.330621858127415\n",
      "Epoch 964 / 1000 loss: 12.330620795488358\n",
      "Epoch 965 / 1000 loss: 12.33061983808875\n",
      "Epoch 966 / 1000 loss: 12.330618735402822\n",
      "Epoch 967 / 1000 loss: 12.330617744475603\n",
      "Epoch 968 / 1000 loss: 12.330616768449545\n",
      "Epoch 969 / 1000 loss: 12.330615634098649\n",
      "Epoch 970 / 1000 loss: 12.330614684149623\n",
      "Epoch 971 / 1000 loss: 12.330613636411726\n",
      "Epoch 972 / 1000 loss: 12.330612589605153\n",
      "Epoch 973 / 1000 loss: 12.330611588433385\n",
      "Epoch 974 / 1000 loss: 12.330610648728907\n",
      "Epoch 975 / 1000 loss: 12.330609554424882\n",
      "Epoch 976 / 1000 loss: 12.330608564428985\n",
      "Epoch 977 / 1000 loss: 12.330607598647475\n",
      "Epoch 978 / 1000 loss: 12.330606519244611\n",
      "Epoch 979 / 1000 loss: 12.330605478025973\n",
      "Epoch 980 / 1000 loss: 12.330604429356754\n",
      "Epoch 981 / 1000 loss: 12.330603443086147\n",
      "Epoch 982 / 1000 loss: 12.330602458678186\n",
      "Epoch 983 / 1000 loss: 12.330601477995515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 984 / 1000 loss: 12.330600400455296\n",
      "Epoch 985 / 1000 loss: 12.330599422566593\n",
      "Epoch 986 / 1000 loss: 12.33059845957905\n",
      "Epoch 987 / 1000 loss: 12.330597390420735\n",
      "Epoch 988 / 1000 loss: 12.330596421845257\n",
      "Epoch 989 / 1000 loss: 12.33059537038207\n",
      "Epoch 990 / 1000 loss: 12.33059445489198\n",
      "Epoch 991 / 1000 loss: 12.33059342764318\n",
      "Epoch 992 / 1000 loss: 12.330592402257025\n",
      "Epoch 993 / 1000 loss: 12.330591397359967\n",
      "Epoch 994 / 1000 loss: 12.330590369179845\n",
      "Epoch 995 / 1000 loss: 12.330589399673045\n",
      "Epoch 996 / 1000 loss: 12.330588343553245\n",
      "Epoch 997 / 1000 loss: 12.33058737590909\n",
      "Epoch 998 / 1000 loss: 12.330586405470967\n",
      "Epoch 999 / 1000 loss: 12.330585343763232\n"
     ]
    }
   ],
   "source": [
    "# initialising stuff and starting the session\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# defining batch size, number of epochs and learning rate\n",
    "\n",
    "batch_size = 5  # how many images to use together for training\n",
    "hm_epochs =1000    # how many times to go through the entire dataset\n",
    "tot_images = 4000 # total number of images\n",
    "\n",
    "# running the model for a 1000 epochs taking 100 images in batches\n",
    "# total improvement is printed out after each epoch\n",
    "\n",
    "for epoch in range(hm_epochs):\n",
    "\n",
    "    epoch_loss = 0    # initializing error as 0\n",
    "\n",
    "    for i in range(int(tot_images/batch_size)):\n",
    "\n",
    "        epoch_x = tdata[ i*batch_size : (i+1)*batch_size ]\n",
    "\n",
    "        _, c = sess.run([optimizer, meansq],\\\n",
    "               feed_dict={input_layer: epoch_x, \\\n",
    "               output_true: epoch_x})\n",
    "\n",
    "        epoch_loss += c\n",
    "\n",
    "    print('Epoch', epoch, '/', hm_epochs, 'loss:',epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
